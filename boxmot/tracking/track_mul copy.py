# Mikel Brostr√∂m üî• Yolo Tracking üßæ AGPL-3.0 license

import os
import argparse
import cv2
import numpy as np
from functools import partial
from pathlib import Path

import torch

from boxmot import TRACKERS
from boxmot.tracker_zoo import create_tracker
from boxmot.utils import ROOT, WEIGHTS, TRACKER_CONFIGS
from boxmot.utils.checks import RequirementsChecker
from .detectors import (get_yolo_inferer, default_imgsz,
                                is_ultralytics_model, is_yolox_model)

checker = RequirementsChecker()
checker.check_packages(('ultralytics @ git+https://github.com/mikel-brostrom/ultralytics.git', ))  # install

from ultralytics import YOLO
from ultralytics.engine.results import Results
from ultralytics.utils.plotting import Annotator, colors
from ultralytics.data.utils import VID_FORMATS
from ultralytics.utils.plotting import save_one_box

import pdb


# IDÈáçÊò†Â∞ÑÂäüËÉΩ
class IDMapper:
    def __init__(self):
        self.id_mapping = {}  # ÂéüÂßãID -> Êñ∞IDÁöÑÊò†Â∞Ñ
        self.next_id = 1      # ‰∏ã‰∏Ä‰∏™ÂèØÁî®ÁöÑÊñ∞ID
        
    def get_mapped_id(self, original_id):
        """Ëé∑ÂèñÊò†Â∞ÑÂêéÁöÑIDÔºåÂ¶ÇÊûúÊòØÊñ∞IDÂàôÂàõÂª∫Êò†Â∞Ñ"""
        if original_id not in self.id_mapping:
            self.id_mapping[original_id] = self.next_id
            self.next_id += 1
        return self.id_mapping[original_id]
    
    def reset_mapping(self):
        """ÈáçÁΩÆIDÊò†Â∞Ñ"""
        self.id_mapping = {}
        self.next_id = 1


def custom_id_processing(tracks, id_mapper, frame_count=None):
    """
    Ëá™ÂÆö‰πâIDÂ§ÑÁêÜÈÄªËæë
    
    Args:
        tracks: Ë∑üË∏™ÁªìÊûú [x1, y1, x2, y2, track_id, conf, cls, ...]
        id_mapper: IDÊò†Â∞ÑÂô®ÂÆû‰æã
        frame_count: ÂΩìÂâçÂ∏ßÊï∞ÔºàÂèØÈÄâÔºâ
    
    Returns:
        Â§ÑÁêÜÂêéÁöÑË∑üË∏™ÁªìÊûú
    """
    if tracks is None or len(tracks) == 0:
        return tracks
    
    processed_tracks = []
    for track in tracks:
        if len(track) >= 5:  # Á°Æ‰øùÊúâtrack_id
            # Ëé∑ÂèñÂéüÂßãIDÔºàÈÄöÂ∏∏Âú®Á¥¢Âºï4ÁöÑ‰ΩçÁΩÆÔºâ
            original_id = int(track[4])            # Â∞ÜÊâÄÊúâIDËÆæ‰∏∫0Áî®‰∫éÊµãËØï
            # new_id = id_mapper.get_mapped_id(original_id)
            new_id = 0
            # ÂàõÂª∫Êñ∞ÁöÑtrackÂâØÊú¨
            new_track = track.copy()
            new_track[4] = new_id
            
            # ÂèØ‰ª•Âú®ËøôÈáåÊ∑ªÂä†ÂÖ∂‰ªñËá™ÂÆö‰πâÈÄªËæë
            # ‰æãÂ¶ÇÔºöÊ†πÊçÆ‰ΩçÁΩÆ„ÄÅÊó∂Èó¥Á≠âÊù°‰ª∂‰øÆÊîπID
            # if frame_count is not None and frame_count % 100 == 0:
            #     # ÊØè100Â∏ßÈáçÊñ∞ÂàÜÈÖçID
            #     new_id = id_mapper.get_mapped_id(original_id + 1000)
            
            processed_tracks.append(new_track)
        else:
            processed_tracks.append(track)
    
    return processed_tracks


def on_predict_start(predictor, persist=False):
    """
    Initialize trackers for object tracking during prediction.

    Args:
        predictor (object): The predictor object to initialize trackers for.
        persist (bool, optional): Whether to persist the trackers if they already exist. Defaults to False.
    """

    assert predictor.custom_args.tracking_method in TRACKERS, \
        f"'{predictor.custom_args.tracking_method}' is not supported. Supported ones are {TRACKERS}"

    tracking_config = TRACKER_CONFIGS / (predictor.custom_args.tracking_method + '.yaml')
    trackers = []
    for i in range(predictor.dataset.bs):
        tracker = create_tracker(
            predictor.custom_args.tracking_method,
            tracking_config,
            predictor.custom_args.reid_model,
            predictor.device,
            predictor.custom_args.half,
            predictor.custom_args.per_class
        )
        # motion only modeles do not have
        if hasattr(tracker, 'model'):
            tracker.model.warmup()
        trackers.append(tracker)

    predictor.trackers = trackers


@torch.no_grad()
def run(args):

    if args.imgsz is None:
        args.imgsz = default_imgsz(args.yolo_model)
    yolo = YOLO(
        args.yolo_model if is_ultralytics_model(args.yolo_model)
        else 'yolov8n.pt',
    )
    results = yolo.track(
   
        source=args.source,
        conf=args.conf,
        iou=args.iou,
        agnostic_nms=args.agnostic_nms,
        show=False,
        stream=True,
        device=args.device,
        show_conf=args.show_conf,
        save_txt=args.save_txt,
        show_labels=args.show_labels,
       
        verbose=args.verbose,
        exist_ok=args.exist_ok,
        project=args.project,
        name=args.name,
        classes=args.classes,
        imgsz=args.imgsz,
        vid_stride=args.vid_stride,
        line_width=args.line_width
    )

    yolo.add_callback('on_predict_start', partial(on_predict_start, persist=True))

    if not is_ultralytics_model(args.yolo_model):
        # replace yolov8 model
        m = get_yolo_inferer(args.yolo_model)
        yolo_model = m(model=args.yolo_model, device=yolo.predictor.device,
                       args=yolo.predictor.args)
        yolo.predictor.model = yolo_model

        # If current model is YOLOX, change the preprocess and postprocess
        if not is_ultralytics_model(args.yolo_model):
            # add callback to save image paths for further processing
            yolo.add_callback(
                "on_predict_batch_start",
                lambda p: yolo_model.update_im_paths(p)
            )
            yolo.predictor.preprocess = (
                lambda imgs: yolo_model.preprocess(im=imgs))
            yolo.predictor.postprocess = (
                lambda preds, im, im0s:
                yolo_model.postprocess(preds=preds, im=im, im0s=im0s))

    # store custom args in predictor
    yolo.predictor.custom_args = args    # ÂàùÂßãÂåñIDÊò†Â∞ÑÂô®
    id_mapper = IDMapper()
    frame_count = 0

    # ÂàùÂßãÂåñ‰øùÂ≠òÁõ∏ÂÖ≥ÂèòÈáè
    all_imgs = []
    save_dir = None
    if args.save or args.save_video:
        save_dir = Path(args.project) / args.name
        save_dir.mkdir(parents=True, exist_ok=True)
        print(f"ËæìÂá∫Â∞Ü‰øùÂ≠òÂà∞: {save_dir}")

    for r in results:
        frame_count += 1
        
        # Ê£ÄÊü•ÊòØÂê¶ÈúÄË¶ÅÈáçÁΩÆIDÊò†Â∞Ñ
        if hasattr(args, 'reset_id_interval') and args.reset_id_interval > 0:
            if frame_count % args.reset_id_interval == 0:
                id_mapper.reset_mapping()
                print(f"Frame {frame_count}: ID mapping reset")
        
        # Ëé∑ÂèñÂéüÂßãË∑üË∏™ÁªìÊûú
        if hasattr(r, 'boxes') and r.boxes is not None:
            # ‰ªéresults‰∏≠ÊèêÂèñË∑üË∏™‰ø°ÊÅØ
            if hasattr(r.boxes, 'id') and r.boxes.id is not None:
                # ÊûÑÂª∫tracksÊ†ºÂºè: [x1, y1, x2, y2, id, conf, cls]
                boxes = r.boxes.xyxy.cpu().numpy()
                ids = r.boxes.id.cpu().numpy()
                confs = r.boxes.conf.cpu().numpy()
                classes = r.boxes.cls.cpu().numpy()
                
                tracks = []
                for i in range(len(boxes)):
                    track = [
                        boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3],  # x1,y1,x2,y2
                        ids[i],      # track_id
                        confs[i],    # confidence
                        classes[i]   # class
                    ]
                    tracks.append(track)
                
                # Âº∫Âà∂Â∞ÜÊâÄÊúâIDËÆæ‰∏∫0ÔºàÊµãËØïÁî®Ôºâ
                processed_tracks = custom_id_processing(tracks, id_mapper, frame_count)
                
                # Â∞ÜÂ§ÑÁêÜÂêéÁöÑIDÂÜôÂõûÂà∞results‰∏≠
                if processed_tracks and len(processed_tracks) > 0:
                    new_ids = [track[4] for track in processed_tracks]                    # ÂàõÂª∫Êñ∞ÁöÑboxesÂº†ÈáèÔºåÂåÖÂê´Êõ¥Êñ∞ÁöÑID
                    if r.boxes is not None and len(r.boxes) > 0:
                        # Ëé∑ÂèñÂéüÂßãboxesÊï∞ÊçÆÂπ∂ÂÖãÈöÜÈÅøÂÖçÂ∞±Âú∞Êõ¥Êñ∞ÈîôËØØ                        if len(new_ids) == len(r.boxes):
                            # ËÆ∞ÂΩï‰øÆÊîπÂâçÁöÑIDÔºàÁ¨¨5ÂàóÔºåÁ¥¢Âºï4Ôºâ
                            original_ids = r.boxes.data[:, 4].cpu().numpy()
                            
                            # ÂÖãÈöÜÊï∞ÊçÆÂπ∂‰øÆÊîπIDÂàóÔºàÁ¨¨5ÂàóÔºåÁ¥¢Âºï4Ôºâ
                            new_data = r.boxes.data.clone()
                            new_data[:, 4] = torch.tensor(new_ids, dtype=new_data.dtype).to(new_data.device)
                            r.boxes.data = new_data
                            
                            # È™åËØÅ‰øÆÊîπÂêéÁöÑID
                            modified_ids = r.boxes.data[:, 4].cpu().numpy()
                            
                            # ‰øùÂ≠òË∞ÉËØï‰ø°ÊÅØÂà∞Êñá‰ª∂
                            debug_file_path = os.path.join(args.project, args.name, 'id_debug.txt')
                            os.makedirs(os.path.dirname(debug_file_path), exist_ok=True)
                            
                            with open(debug_file_path, 'a', encoding='utf-8') as f:
                                f.write(f"\n=== Frame {frame_count} ===\n")
                                f.write(f"Ê£ÄÊµãÂà∞ÁõÆÊ†áÊï∞Èáè: {len(new_ids)}\n")
                                f.write(f"ÂéüÂßãIDs: {original_ids}\n")
                                f.write(f"‰øÆÊîπÂêéÁöÑIDs: {modified_ids}\n")
                                f.write(f"È¢ÑÊúüÁöÑnew_ids: {new_ids}\n")
                                
                                # È™åËØÅr.boxes.idÂ±ûÊÄßÔºàÂ¶ÇÊûúÂ≠òÂú®Ôºâ
                                if hasattr(r.boxes, 'id') and r.boxes.id is not None:
                                    boxes_id_values = r.boxes.id.cpu().numpy()
                                    f.write(f"r.boxes.idÂ±ûÊÄßÂÄº: {boxes_id_values}\n")
                                
                                # È™åËØÅ‰øÆÊîπÊòØÂê¶ÊàêÂäü
                                modification_success = all(id_val == 0 for id_val in modified_ids)
                                f.write(f"ID‰øÆÊîπÊàêÂäü: {modification_success}\n")
                                f.write("-" * 50 + "\n")
                    
                    # ÊâìÂç∞IDÊò†Â∞Ñ‰ø°ÊÅØ
                    if frame_count % 30 == 0:  # ÊØè30Â∏ßÊâìÂç∞‰∏ÄÊ¨°
                        print(f"Frame {frame_count}: ÊâÄÊúâIDÂ∑≤ËÆæ‰∏∫0ÔºåÊ£ÄÊµãÂà∞ {len(new_ids)} ‰∏™ÁõÆÊ†á")
        
        # ÁªòÂà∂ÁªìÊûú
        img = r.orig_img.copy()
        
        # Â¶ÇÊûúÊúâÊ£ÄÊµãÁªìÊûúÔºåÁõ¥Êé•Âú®ÂõæÂÉè‰∏äÁªòÂà∂
        if hasattr(r, 'boxes') and r.boxes is not None and len(r.boxes) > 0:
            annotator = Annotator(img, line_width=args.line_width)
            
            for i, box in enumerate(r.boxes.xyxy):
                # Ëé∑ÂèñÊ°ÜÂùêÊ†á
                x1, y1, x2, y2 = box.cpu().numpy()
                  # Ëé∑ÂèñIDÔºà‰ªéÁ¨¨5ÂàóÔºåÁ¥¢Âºï4Ëé∑Âèñ‰øÆÊîπÂêéÁöÑtrack_idÔºâ
                track_id = int(r.boxes.data[i, 4].cpu().numpy()) if r.boxes.data.shape[1] > 4 else 0
                
                # Ëé∑ÂèñÁΩÆ‰ø°Â∫¶ÂíåÁ±ªÂà´
                conf = r.boxes.conf[i].cpu().numpy() if hasattr(r.boxes, 'conf') else 0.0
                cls = int(r.boxes.cls[i].cpu().numpy()) if hasattr(r.boxes, 'cls') else 0
                
                # ÊûÑÂª∫Ê†áÁ≠æ
                label = f"ID:{track_id}"
                if args.show_conf:
                    label += f" {conf:.2f}"
                if args.show_labels and hasattr(r, 'names'):
                    label += f" {r.names[cls]}"
                  # ÁªòÂà∂Ê°ÜÂíåÊ†áÁ≠æ - ‰ΩøÁî®Á±ªÂà´IDÂÜ≥ÂÆöÈ¢úËâ≤
                annotator.box_label((x1, y1, x2, y2), label, color=colors(cls, True))
            
            img = annotator.result()
        else:
            # Â¶ÇÊûúÊ≤°Êúâ‰øÆÊîπÂêéÁöÑresultsÔºå‰ΩøÁî®ÂéüÂßãtrackerÁªòÂà∂
            img = yolo.predictor.trackers[0].plot_results(r.orig_img, args.show_trajectories)        # ‰øùÂ≠òÁªìÊûú
        if args.save or args.save_video:
            # ÂàõÂª∫‰øùÂ≠òÁõÆÂΩï
            save_dir = Path(args.project) / args.name
            save_dir.mkdir(parents=True, exist_ok=True)
            
            # ‰øùÂ≠òÂçïÂº†ÂõæÁâáÔºàÂ¶ÇÊûúÂêØÁî®‰∫ÜsaveÔºâ
            if args.save:
                img_path = save_dir / f"frame_{frame_count:06d}.jpg"
                cv2.imwrite(str(img_path), img)
            
            # Êî∂ÈõÜÁî®‰∫éËßÜÈ¢ë‰øùÂ≠òÁöÑÂõæÁâá
            if args.save_video:
                all_imgs.append(img)

        if args.show is True:
            cv2.imshow('BoxMOT', img)     
            key = cv2.waitKey(1) & 0xFF
            if key == ord(' ') or key == ord('q'):
                break

    # ‰øùÂ≠òËßÜÈ¢ëÔºàÂ¶ÇÊûúÊî∂ÈõÜ‰∫ÜÂõæÁâáÔºâ
    if args.save_video and len(all_imgs) > 0:
        save_dir = Path(args.project) / args.name
        save_dir.mkdir(parents=True, exist_ok=True)
        video_path = save_dir / 'tracking_output.mp4'
        
        frame_size = all_imgs[0].shape[1], all_imgs[0].shape[0]
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        fps = 30  # ‰ΩøÁî®Êõ¥ÂêàÁêÜÁöÑÂ∏ßÁéá
        out = cv2.VideoWriter(str(video_path), fourcc, fps, frame_size)
        for img in all_imgs:
            out.write(img)
        out.release()
        print(f"ËßÜÈ¢ëÂ∑≤‰øùÂ≠òÂà∞: {video_path}")


def parse_opt():
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--yolo-model', type=Path, default=WEIGHTS / 'yolov8n',
                        help='yolo model path')
    parser.add_argument('--reid-model', type=Path, default=WEIGHTS / 'osnet_x0_25_msmt17.pt',
                        help='reid model path')
    parser.add_argument('--tracking-method', type=str, default='deepocsort',
                        help='deepocsort, botsort, strongsort, ocsort, bytetrack, imprassoc, boosttrack')
    parser.add_argument('--source', type=str, default='0',
                        help='file/dir/URL/glob, 0 for webcam')
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=None,
                        help='inference size h,w')
    parser.add_argument('--conf', type=float, default=0.5,
                        help='confidence threshold')
    parser.add_argument('--iou', type=float, default=0.7,
                        help='intersection over union (IoU) threshold for NMS')
    parser.add_argument('--device', default='',
                        help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--show', action='store_true',
                        help='display tracking video results')
    parser.add_argument('--save', action='store_true',
                        help='save video tracking results')
    parser.add_argument('--save-video', action='store_true',
                        help='save video tracking results in .mp4 format')

    # class 0 is person, 1 is bycicle, 2 is car... 79 is oven
    parser.add_argument('--classes', nargs='+', type=int,
                        help='filter by class: --classes 0, or --classes 0 2 3')
    parser.add_argument('--project', default=ROOT / 'runs' / 'track',
                        help='save results to project/name')
    parser.add_argument('--name', default='exp',
                        help='save results to project/name')
    parser.add_argument('--exist-ok', action='store_true',
                        help='existing project/name ok, do not increment')
    parser.add_argument('--half', action='store_true',
                        help='use FP16 half-precision inference')
    parser.add_argument('--vid-stride', type=int, default=1,
                        help='video frame-rate stride')
    parser.add_argument('--show-labels', action='store_false',
                        help='either show all or only bboxes')
    parser.add_argument('--show-conf', action='store_false',
                        help='hide confidences when show')
    parser.add_argument('--show-trajectories', action='store_true',
                        help='show confidences')
    parser.add_argument('--save-txt', action='store_true',
                        help='save tracking results in a txt file')
    parser.add_argument('--save-id-crops', action='store_true',
                        help='save each crop to its respective id folder')
    parser.add_argument('--line-width', default=None, type=int,
                        help='The line width of the bounding boxes. If None, it is scaled to the image size.')
    parser.add_argument('--per-class', default=False, action='store_true',
                        help='not mix up classes when tracking')
    parser.add_argument('--verbose', default=True, action='store_true',
                        help='print results per frame')
    parser.add_argument('--agnostic-nms', default=False, action='store_true',
                        help='class-agnostic NMS')
    parser.add_argument('--id-remapping', action='store_true',
                        help='enable custom ID remapping')
    parser.add_argument('--reset-id-interval', type=int, default=0,
                        help='reset ID mapping every N frames (0 = disabled)')

    opt = parser.parse_args()
    return opt


if __name__ == "__main__":
    opt = parse_opt()
    run(opt)
